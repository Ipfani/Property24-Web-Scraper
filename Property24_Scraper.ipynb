{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are in page:  1\n",
      "We are in page:  2\n",
      "We are in page:  3\n",
      "We are in page:  4\n",
      "We are in page:  5\n",
      "We are in page:  6\n",
      "We are in page:  7\n",
      "We are in page:  8\n",
      "We are in page:  9\n",
      "We are in page:  10\n",
      "We are in page:  11\n",
      "We are in page:  12\n",
      "We are in page:  13\n",
      "We are in page:  14\n",
      "We are in page:  15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 57\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (max_pages):  \n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# website = requests.get('https://www.property24.com/for-sale/simons-town/western-cape/401/p' + str(i))\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m#website = requests.get('https://www.property24.com/for-sale/simons-town/western-cape/401/p' + str(i)) #Test pages from western cape\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     website \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.property24.com/for-sale/mossel-bay/western-cape/317/p\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)) \u001b[38;5;66;03m#Mossel Bay\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(website\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m#Title\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     titles \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m\"\u001b[39m, itemprop\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py:328\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m rejections \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    327\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_encoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeclared_html_encoding,\n\u001b[0;32m    329\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontains_replacement_characters) \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m    330\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mprepare_markup(\n\u001b[0;32m    331\u001b[0m          markup, from_encoding, exclude_encodings\u001b[38;5;241m=\u001b[39mexclude_encodings)):\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py:361\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.prepare_markup\u001b[1;34m(self, markup, user_specified_encoding, document_declared_encoding, exclude_encodings)\u001b[0m\n\u001b[0;32m    358\u001b[0m user_encodings \u001b[38;5;241m=\u001b[39m [document_declared_encoding]\n\u001b[0;32m    360\u001b[0m try_encodings \u001b[38;5;241m=\u001b[39m [user_specified_encoding, document_declared_encoding]\n\u001b[1;32m--> 361\u001b[0m dammit \u001b[38;5;241m=\u001b[39m UnicodeDammit(\n\u001b[0;32m    362\u001b[0m     markup,\n\u001b[0;32m    363\u001b[0m     known_definite_encodings\u001b[38;5;241m=\u001b[39mknown_definite_encodings,\n\u001b[0;32m    364\u001b[0m     user_encodings\u001b[38;5;241m=\u001b[39muser_encodings,\n\u001b[0;32m    365\u001b[0m     is_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    366\u001b[0m     exclude_encodings\u001b[38;5;241m=\u001b[39mexclude_encodings\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (dammit\u001b[38;5;241m.\u001b[39mmarkup, dammit\u001b[38;5;241m.\u001b[39moriginal_encoding,\n\u001b[0;32m    369\u001b[0m        dammit\u001b[38;5;241m.\u001b[39mdeclared_html_encoding,\n\u001b[0;32m    370\u001b[0m        dammit\u001b[38;5;241m.\u001b[39mcontains_replacement_characters)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\bs4\\dammit.py:601\u001b[0m, in \u001b[0;36mUnicodeDammit.__init__\u001b[1;34m(self, markup, known_definite_encodings, smart_quotes_to, is_html, exclude_encodings, user_encodings, override_encodings)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mmarkup\n\u001b[0;32m    600\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mencodings:\n\u001b[0;32m    602\u001b[0m     markup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mmarkup\n\u001b[0;32m    603\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_from(encoding)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\bs4\\dammit.py:442\u001b[0m, in \u001b[0;36mEncodingDetector.encodings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;66;03m# Use third-party character set detection to guess at the\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# encoding.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchardet_encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchardet_encoding \u001b[38;5;241m=\u001b[39m chardet_dammit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_usable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchardet_encoding, tried):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchardet_encoding\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\bs4\\dammit.py:46\u001b[0m, in \u001b[0;36mchardet_dammit\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chardet_module\u001b[38;5;241m.\u001b[39mdetect(s)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\chardet\\__init__.py:41\u001b[0m, in \u001b[0;36mdetect\u001b[1;34m(byte_str)\u001b[0m\n\u001b[0;32m     39\u001b[0m         byte_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(byte_str)\n\u001b[0;32m     40\u001b[0m detector \u001b[38;5;241m=\u001b[39m UniversalDetector()\n\u001b[1;32m---> 41\u001b[0m detector\u001b[38;5;241m.\u001b[39mfeed(byte_str)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m detector\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\chardet\\universaldetector.py:211\u001b[0m, in \u001b[0;36mUniversalDetector.feed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_charset_probers\u001b[38;5;241m.\u001b[39mappend(Latin1Prober())\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prober \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_charset_probers:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prober\u001b[38;5;241m.\u001b[39mfeed(byte_str) \u001b[38;5;241m==\u001b[39m ProbingState\u001b[38;5;241m.\u001b[39mFOUND_IT:\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m: prober\u001b[38;5;241m.\u001b[39mcharset_name,\n\u001b[0;32m    213\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m: prober\u001b[38;5;241m.\u001b[39mget_confidence(),\n\u001b[0;32m    214\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m: prober\u001b[38;5;241m.\u001b[39mlanguage}\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\chardet\\charsetgroupprober.py:71\u001b[0m, in \u001b[0;36mCharSetGroupProber.feed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prober\u001b[38;5;241m.\u001b[39mactive:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m state \u001b[38;5;241m=\u001b[39m prober\u001b[38;5;241m.\u001b[39mfeed(byte_str)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\chardet\\sbcharsetprober.py:92\u001b[0m, in \u001b[0;36mSingleByteCharSetProber.feed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed\u001b[39m(\u001b[38;5;28mself\u001b[39m, byte_str):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# TODO: Make filter_international_words keep things in self.alphabet\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mkeep_ascii_letters:\n\u001b[1;32m---> 92\u001b[0m         byte_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_international_words(byte_str)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m byte_str:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\chardet\\charsetprober.py:90\u001b[0m, in \u001b[0;36mCharSetProber.filter_international_words\u001b[1;34m(buf)\u001b[0m\n\u001b[0;32m     86\u001b[0m words \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[a-zA-Z]*[\u001b[39m\u001b[38;5;130;01m\\x80\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;130;01m\\xFF\u001b[39;00m\u001b[38;5;124m]+[a-zA-Z]*[^a-zA-Z\u001b[39m\u001b[38;5;130;01m\\x80\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;130;01m\\xFF\u001b[39;00m\u001b[38;5;124m]?\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     87\u001b[0m                    buf)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m---> 90\u001b[0m     filtered\u001b[38;5;241m.\u001b[39mextend(word[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# If the last character in the word is a marker, replace it with a\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# space as markers shouldn't affect our analysis (they are used\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# similarly across all languages and may thus have similar\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# frequencies).\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     last_char \u001b[38;5;241m=\u001b[39m word[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#********************************************************************\n",
    "#                    DATE FINISHED & UPLOADED                       *\n",
    "#                   05 December 2023 [GMT-2]                        *\n",
    "#                                                                   *\n",
    "#     Author: Ipfani Mutavhatsindi                                  *\n",
    "#     LinkedIn: https://www.linkedin.com/in/ipfani-mutavhatsindi    *       \n",
    "#     Website: https://ipfani.github.io/                            *    \n",
    "#                                                                   *\n",
    "#********************************************************************\n",
    "\n",
    "# I wrote this code because i wanted a spreadsheet of properties for sale which i can use apply my knowledge from WQU - Data Science Lab Course\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd \n",
    "import urllib.parse \n",
    "import pprint\n",
    "\n",
    "\n",
    "#My Declerations\n",
    "\n",
    "#Currently set at 100 pages maximum, It will stop if weblink have less pages than 100.\n",
    "#I can change the value depending on the amount of data i want to collect\n",
    "max_pages = 100\n",
    "\n",
    "#Variable to check the webpage being read\n",
    "page_numbers = 1\n",
    "\n",
    "#Pretty Printer for printing\n",
    "pp = pprint.PrettyPrinter(indent=10)\n",
    "\n",
    "#Website Link\n",
    "#This scraper is based on Property24 template design\n",
    "#Any search link from the website above will work fine\n",
    "#website = 'https://www.property24.com/for-sale/simons-town/western-cape/401' #Simons Town\n",
    "\n",
    "#Variables to store the data, Lists\n",
    "titles = []\n",
    "locations = []\n",
    "prices = []\n",
    "sizes = []\n",
    "\n",
    "#Lets create DataFrame with these headings\n",
    "df_property = pd.DataFrame(columns=['Name', 'Size', 'Price', 'Location'])\n",
    "\n",
    "\n",
    "#********************************************************************************************************************************************\n",
    "#INPUT PART OF THE PROGRAM\n",
    "#Collection of the data\n",
    "\n",
    "for i in range (max_pages):  \n",
    "    # website = requests.get('https://www.property24.com/for-sale/simons-town/western-cape/401/p' + str(i))\n",
    "    #website = requests.get('https://www.property24.com/for-sale/simons-town/western-cape/401/p' + str(i)) #Test pages from western cape\n",
    "    website = requests.get('https://www.property24.com/for-sale/mossel-bay/western-cape/317/p' + str(i)) #Mossel Bay\n",
    "\n",
    "    soup = BeautifulSoup(website.content, 'html.parser')\n",
    "    \n",
    "    #Title\n",
    "    titles = soup.find_all(\"span\", itemprop=\"name\")\n",
    "    \n",
    "    #Break when we nolonger get the data from the webpage\n",
    "    if (len(titles) < 1):\n",
    "        break\n",
    "        \n",
    "    #Location        \n",
    "    locations = soup.find_all('span', class_=['p24_location'])\n",
    "    \n",
    "    #Price\n",
    "    # <span class=\"p24_price\" content=\"2500000\" itemprop=\"price\">\n",
    "    # <meta content=\"ZAR\" itemprop=\"priceCurrency\"/> R 2 500 000 </span>\n",
    "    \n",
    "    prices = soup.find_all('span', itemprop=\"price\")\n",
    "    \n",
    "    \n",
    "    #Now store only sizes values\n",
    "    sizes = soup.find_all(title='Erf Size')\n",
    "    \n",
    "    print(\"We are in page: \", page_numbers )\n",
    "    page_numbers = page_numbers + 1\n",
    "    \n",
    "    for row in range ((min(len(titles), len(prices), len(locations), len(sizes)))):\n",
    "        df_property = pd.concat([df_property, pd.DataFrame.from_records([{'Name':titles[row].string, 'Size' :sizes[row].text.strip()[-9:], 'Price':prices[row].text.strip(), 'Location':locations[row].string }])],  ignore_index=True)\n",
    "        \n",
    "df_property.info()\n",
    "\n",
    "\n",
    "#******************************************************************************************************************************************** \n",
    "#OUTPUT\n",
    "\n",
    "df_property.head()\n",
    "\n",
    "#Write to CSV File\n",
    "# df_property.to_csv('property.csv')\n",
    "df_property.to_csv('Mosel-Bay-property.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Size</th>\n",
       "      <th>Price</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 Bedroom House</td>\n",
       "      <td>\\n\\n\\n598 m²</td>\n",
       "      <td>R 6 200 000</td>\n",
       "      <td>Murdock Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 Bedroom House</td>\n",
       "      <td>\\n1 004 m²</td>\n",
       "      <td>R 8 950 000</td>\n",
       "      <td>Glencairn Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>\\n\\n\\n696 m²</td>\n",
       "      <td>R 2 500 000</td>\n",
       "      <td>Simons Town Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 Bedroom House</td>\n",
       "      <td>\\n\\n\\n321 m²</td>\n",
       "      <td>R 2 495 000</td>\n",
       "      <td>Glencairn Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 Bedroom House</td>\n",
       "      <td>\\n\\n\\n535 m²</td>\n",
       "      <td>R 3 550 000</td>\n",
       "      <td>Simons Kloof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>27 000 m²</td>\n",
       "      <td>R 12 350 000</td>\n",
       "      <td>Glencairn Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 Bedroom House</td>\n",
       "      <td>\\n\\n\\n558 m²</td>\n",
       "      <td>R 3 390 000</td>\n",
       "      <td>Cairnside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5 Bedroom House</td>\n",
       "      <td>\\n\\n\\n613 m²</td>\n",
       "      <td>R 5 150 000</td>\n",
       "      <td>Smitswinkelbaai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name          Size         Price             Location\n",
       "0  3 Bedroom House  \\n\\n\\n598 m²   R 6 200 000       Murdock Valley\n",
       "1  6 Bedroom House    \\n1 004 m²   R 8 950 000    Glencairn Heights\n",
       "2      Vacant Land  \\n\\n\\n696 m²   R 2 500 000  Simons Town Central\n",
       "3  3 Bedroom House  \\n\\n\\n321 m²   R 2 495 000    Glencairn Heights\n",
       "4  3 Bedroom House  \\n\\n\\n535 m²   R 3 550 000         Simons Kloof\n",
       "5      Vacant Land     27 000 m²  R 12 350 000    Glencairn Heights\n",
       "6  4 Bedroom House  \\n\\n\\n558 m²   R 3 390 000            Cairnside\n",
       "7  5 Bedroom House  \\n\\n\\n613 m²   R 5 150 000      Smitswinkelbaai"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_property.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
